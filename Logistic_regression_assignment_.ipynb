{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "\n",
        "Ans:-Logistic regresssion is a type of machine learnig algorithm used to slove  classification problem , it  give output as probability in rang 0 to 1 and uses sigmoid function to squeeze output value between 0 and 1.\n",
        "\n",
        "linear regression is used to slove regressin problem and rep straight line and logistic regressionis used for classification problem and rep sigmoid curve.\n",
        "\n",
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "\n",
        "Ans:-In Logistic Regression, the sigmoid function is used to convert the linear output into a probability value between 0 and 1.\n",
        "It ensures that predictions are interpretable as probabilities.\n",
        "The function has an S-shaped curve that smoothly maps inputs.\n",
        "This helps in handling classification problems effectively.\n",
        "A threshold (like 0.5) is applied to decide the final class label.\n",
        "It also provides confidence levels for predictions instead of just binary results.\n",
        "Being differentiable, it supports optimization through gradient descent.\n",
        "\n",
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "\n",
        "Ans:-Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the cost function. In logistic regression, the model tries to fit the data by estimating coefficients (weights). If the coefficients become very large, the model may fit the training data perfectly but perform poorly on unseen data (overfitting). Regularization controls this by discouraging extremely large weight values.\n",
        "\n",
        "There are mainly two types of regularization:\n",
        "\n",
        "L1 (Lasso) Regularization – adds the absolute values of coefficients as a penalty, which can shrink some coefficients to zero and perform feature selection.\n",
        "\n",
        "L2 (Ridge) Regularization – adds the squared values of coefficients as a penalty, which keeps coefficients small but not exactly zero.\n",
        "\n",
        "Regularization is needed because it improves the generalization ability of the model, reduces variance, and makes predictions more stable and reliable on new data.\n",
        "\n",
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "Ans:-In classification models, common evaluation metrics include Accuracy, Precision, Recall, F1-Score, and ROC-AUC. Accuracy measures the overall correctness of predictions, but it can be misleading when classes are imbalanced. Precision indicates how many of the predicted positives are actually correct, while Recall measures how many of the actual positives are identified by the model. The F1-Score combines Precision and Recall into a single metric, useful when both false positives and false negatives matter. ROC-AUC evaluates the model’s ability to distinguish between classes at different thresholds. These metrics are important because they provide deeper insights into model performance beyond just accuracy, ensuring the model is reliable and effective in real-world scenarios.\n",
        "\n",
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "\n",
        "Ans:-# Question 5: Logistic Regression Program\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)  # increased iterations to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression model:\", accuracy)\n",
        "\n",
        "\n",
        "Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy\n",
        "\n",
        "Ans:-# Question 6: Logistic Regression with L2 Regularization (Ridge)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with L2 regularization (default penalty='l2')\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Model Coefficients:\\n\", model.coef_)\n",
        "print(\"\\nIntercept:\\n\", model.intercept_)\n",
        "print(\"\\nAccuracy of Logistic Regression with L2 Regularization:\", accuracy)\n",
        "\n",
        "\n",
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "\n",
        "Ans:-# Question 7: Logistic Regression for Multiclass Classification (OvR)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset (Iris dataset for multiclass classification)\n",
        "data = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with OvR strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
        "\n",
        "\n",
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "\n",
        "Ans:-\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],       # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],            # L1 = Lasso, L2 = Ridge\n",
        "    'solver': ['liblinear']             # 'liblinear' supports both l1 and l2\n",
        "}\n",
        "\n",
        "# Logistic Regression with GridSearchCV\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters found:\", grid.best_params_)\n",
        "\n",
        "# Best cross-validation accuracy\n",
        "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n",
        "\n",
        "# Test set accuracy using best model\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Test Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "Ans:-\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train-Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=10000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model_scaling = LogisticRegression(max_iter=10000)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy without Scaling:\", accuracy_no_scaling)\n",
        "print(\"Accuracy with Scaling   :\", accuracy_scaling)\n",
        "\n",
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "\n",
        "\n",
        "Ans:-Start with data preprocessing: clean missing values, encode categorical features, and remove outliers.\n",
        "\n",
        "Use a stratified train-test split to preserve the 5% responder ratio in both sets.\n",
        "\n",
        "Apply feature scaling (StandardScaler or MinMaxScaler) to improve model convergence.\n",
        "\n",
        "Handle class imbalance using SMOTE (oversampling) or undersampling, or set class_weight='balanced'.\n",
        "\n",
        "Train a Logistic Regression model with both L1 and L2 penalties.\n",
        "\n",
        "Use GridSearchCV to tune hyperparameters like C (regularization strength) and penalty.\n",
        "\n",
        "Optimize the decision threshold (not just 0.5) based on business goals.\n",
        "\n",
        "Evaluate using Precision, Recall, F1-score, ROC-AUC, and PR-AUC instead of accuracy.\n",
        "\n",
        "Focus on Recall if the goal is reaching more responders, or Precision if minimizing campaign cost is key.\n",
        "\n",
        "Deploy the best model and monitor performance continuously on new customer data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kOfowOv1gQos"
      }
    }
  ]
}